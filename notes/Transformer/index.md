---
lastUpdated: false
---

# 深度学习架构

Transformer架构、注意力机制、混合专家模型、扩散模型等深度学习核心架构笔记。

<div class="card-grid">

<a href="/notes/Transformer/The_Illustrated_Transformer/note" class="card">
<div class="card-title">📖 The Illustrated Transformer</div>
<div class="card-desc">Transformer架构图解与详细讲解</div>
<div class="card-meta">2026-02-13</div>
</a>

<a href="/notes/Transformer/MHA_and_MLA/note" class="card">
<div class="card-title">🧠 MHA and MLA</div>
<div class="card-desc">多头注意力与多层注意力机制对比</div>
<div class="card-meta">2026-02-26</div>
</a>

<a href="/notes/Transformer/Softmax/note" class="card">
<div class="card-title">🔥 Softmax</div>
<div class="card-desc">深度理解Softmax函数原理与应用</div>
<div class="card-meta">2026-02-26</div>
</a>

<a href="/notes/Transformer/MoE/MoE" class="card">
<div class="card-title">🌀 MoE</div>
<div class="card-desc">混合专家模型：从1991到2024的演进与工程挑战</div>
<div class="card-meta">2026-02-27</div>
</a>

<a href="/notes/Transformer/Difussion_and_DiT/note" class="card">
<div class="card-title">🎨 Diffusion and DiT</div>
<div class="card-desc">扩散模型、U-Net与Diffusion Transformer详解</div>
<div class="card-meta">2026-02-27</div>
</a>

</div>
