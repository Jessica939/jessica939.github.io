

### 1. vLLM 的核心改进：解决“阻塞”与“复用”

vLLM最早提出了PagedAttention，但最近它为了解决**长文本（Long Context）**和**高并发**，搞了两个大动作，这跟你的“调度优化”直接相关：

#### A. Chunked Prefill（分块预填充）—— *关键！最适合写进周报*
*   **背景痛点：** 以前的Continuous Batching有一个问题：虽然Decode阶段是并行的，但如果突然来了一个Prompt特别长的请求（Prefill阶段），它会霸占GPU很长时间，导致其他正在生成Token的小请求卡顿（Head-of-Line Blocking）。
*   **改进方案：** vLLM现在支持把那个超长的Prompt**切成小块（Chunks）**，分多次喂给GPU。
*   **对你的启示：** 这样一来，在处理长Prompt的间隙，调度器可以“插空”让其他短请求继续生成Token。这就是**计算密集型（Prefill）和显存密集型（Decode）的混合调度**，完美契合你想做的“动态调度”。

#### B. Automatic Prefix Caching (APC) —— *提升利用率*
*   **机制：** 系统会自动识别不同请求之间**公共的前缀（Prompt Prefix）**。比如大家都用同一个System Prompt（“你是一个有用的助手...”），这部分KV Cache会被驻留在显存里，不释放，供所有请求共享。
*   **对你的启示：** 显存管理不再是“用完即扔”，而是变成了带有LRU（最近最少使用）策略的缓存池。这能大幅降低首字延迟（TTFT）。

---

### 2. SGLang 的核心改进：RadixAttention

SGLang（LMSYS团队做的，比vLLM更激进）最近非常火，它的核心理念完全颠覆了传统的PagedAttention。

#### A. RadixAttention（基数注意力/树状缓存）
*   **核心机制：** 它的KV Cache管理不仅仅是“页（Page）”，而是一棵**前缀树（Radix Tree）**。
*   **场景：** 当你做多轮对话，或者让模型“自我反思”（Tree of Thoughts）时，会有很多分叉。SGLang能自动保留父节点的KV Cache。
*   **相比vLLM的区别：** vLLM主要优化的是“并行的请求”，SGLang优化的是“结构化的、有上下文关联的请求”。它的缓存命中率通常比vLLM高很多。
*   **对你的启示：** 如果你的系统未来要支持多轮对话优化，阅读SGLang的源码通过Radix Tree来管理显存索引是最佳参考。

#### B. 极致的算子优化（FlashInfer）
*   SGLang底层大量使用了FlashInfer kernel，针对不同长度的Attention做了极致的Mask优化，这使得它在调度开销上比vLLM更小。

---

### 3. 如何把这些编进周报里？（抄作业版）

你可以把上面学到的词汇组合一下，显得你进行了深度的**竞品架构对比**：

> **周报条目建议：**
>
> **1. 业界前沿调度机制深度调研（vLLM & SGLang）：**
> *   **Chunked Prefill机制分析：** 深入研究了vLLM通过**Chunked Prefill**解决长文本推理导致Head-of-Line Blocking（队头阻塞）的实现方案。这对我们后续优化长短任务混合并行的调度策略提供了直接参考。
> *   **KV Cache复用策略对比：** 对比了vLLM的Prefix Caching与SGLang的**RadixAttention**（基于前缀树的缓存管理）。
> *   **结论：** 发现SGLang在处理多轮对话场景下，通过Radix Tree维护KV Cache映射关系的效率更高，计划后续在我们的显存管理模块中借鉴该设计思路，以降低Redundant Computation（冗余计算）。

**技术名词解释（防身用）：**
*   如果领导问你什么叫**Chunked Prefill**？
    *   答：就是把长文章切碎了喂给GPU，中间允许别人的短任务插队，防止一个大任务把路堵死。
*   如果问什么叫**RadixAttention**？
    *   答：就是像文件目录树一样管理显存，父目录（上文）存好了，子目录（不同的下文）可以直接用，不用重新算。

这一套下来，既有广度（看了两个项目），又有深度（Chunked Prefill/RadixAttention），足够应付周会了。